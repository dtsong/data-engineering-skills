## Contents

- [dbt Artifacts as Deliverables](#dbt-artifacts-as-deliverables)
- [Security Tier Awareness](#security-tier-awareness)
- [Project Portability for Client Handoff](#project-portability-for-client-handoff)
- [Client-Facing Documentation](#client-facing-documentation)

---

# Consulting Workflow

> **Part of:** [dbt-skill](../SKILL.md)

## dbt Artifacts as Deliverables

dbt generates structured artifacts after every run. Use them as engagement deliverables.

| Artifact | Location | Deliverable Use |
|----------|----------|----------------|
| `manifest.json` | `target/` | Full DAG lineage -- show clients data flow from source to mart |
| `catalog.json` | `target/` | Column-level documentation -- generated by `dbt docs generate` |
| `run_results.json` | `target/` | Execution log -- proves all models/tests passed |
| `sources.json` | `target/` | Source freshness report -- shows data pipeline health |

### Lineage Report from manifest.json

```bash
# Generate docs (creates both catalog.json and updates manifest.json)
dbt docs generate

# Serve locally for client walkthrough
dbt docs serve --port 8080
```

Extract model lineage programmatically for reports:

```python
import json

with open("target/manifest.json") as f:
    manifest = json.load(f)

for node_id, node in manifest["nodes"].items():
    if node["resource_type"] == "model":
        print(f"{node['name']} depends on: {node['depends_on']['nodes']}")
```

### Quality Report from run_results.json

Summarize test results for client status reports:

```python
import json

with open("target/run_results.json") as f:
    results = json.load(f)

tests = [r for r in results["results"] if r["unique_id"].startswith("test.")]
passed = sum(1 for t in tests if t["status"] == "pass")
failed = sum(1 for t in tests if t["status"] == "fail")
print(f"Tests: {passed} passed, {failed} failed out of {len(tests)}")
```

## Security Tier Awareness

See [Consulting Security Tier Model](../../shared-references/data-engineering/security-tier-model.md) for the full tier framework.

Adapt dbt project configuration to the engagement's security tier.

| Tier | Profile Config | Data Access | Recommended dbt Target |
|------|---------------|-------------|----------------------|
| **Tier 1: Schema-Only** | No warehouse credentials | Schema metadata only | DuckDB with `information_schema` export |
| **Tier 2: Sampled** | DuckDB with sample data | Anonymized/sampled extracts | `dbt run --target dev` (DuckDB) |
| **Tier 3: Full Access** | Warehouse credentials via `env_var()` | Full production data | `dbt run --target prod` |

### Tier 1 Profile (Schema-Only)

```yaml
client_project:
  target: schema_only
  outputs:
    schema_only:
      type: duckdb
      path: ":memory:"
```

Load only `information_schema` exports or DDL statements. Build models as views referencing empty schema tables. Validate SQL compilation with `dbt compile` without executing.

### Tier 2 Profile (Sampled Data)

```yaml
client_project:
  target: dev
  outputs:
    dev:
      type: duckdb
      path: "target/client_sample.duckdb"
```

Load anonymized sample CSVs into DuckDB. Run full `dbt build` cycle locally. All cleaning, testing, and documentation work is possible.

### Tier 3 Profile (Full Access)

```yaml
client_project:
  target: prod
  outputs:
    prod:
      type: snowflake
      account: "{{ env_var('CLIENT_SNOWFLAKE_ACCOUNT') }}"
      user: "{{ env_var('CLIENT_SNOWFLAKE_USER') }}"
      authenticator: externalbrowser    # SSO preferred
      database: analytics
      warehouse: transforming
      schema: dbt_consultant
```

Use a dedicated schema (`dbt_consultant`) to isolate consultant work from production models.

## Project Portability for Client Handoff

Structure the project so the client can run it independently after handoff.

### Self-Contained Repository

```
client_dbt_project/
├── dbt_project.yml
├── packages.yml
├── requirements.txt          # pip install dbt-core dbt-snowflake
├── profiles.yml.example      # Template -- never the real one
├── .env.example              # Document required env vars
├── README.md                 # Setup + run instructions
├── models/
├── macros/
├── tests/
├── seeds/
└── data/                     # Sample data for DuckDB dev target
```

### requirements.txt

```
dbt-core==1.9.0
dbt-snowflake==1.9.0
dbt-duckdb==1.9.0
```

Pin exact versions. Document the dbt version used during development.

### Environment Variable Documentation

Create `.env.example` listing every required variable:

```bash
# .env.example -- copy to .env and fill in values
SNOWFLAKE_ACCOUNT=your_account.region
SNOWFLAKE_USER=your_user
SNOWFLAKE_ROLE=transformer
SNOWFLAKE_WAREHOUSE=transforming
SNOWFLAKE_DATABASE=analytics
```

### Handoff Checklist

1. All models compile and pass tests on the client's target.
2. `packages.yml` lists all dependencies with pinned versions.
3. `requirements.txt` pins the dbt version.
4. `.env.example` documents every `env_var()` reference.
5. `profiles.yml.example` shows the expected profile structure.
6. `README.md` contains setup, run, and troubleshooting instructions.
7. Sample data exists for DuckDB dev target.

## Client-Facing Documentation

### dbt docs generate

Generate browsable documentation:

```bash
dbt docs generate
dbt docs serve
```

### Model Descriptions

Add descriptions in YAML for every mart and key intermediate model:

```yaml
models:
  - name: fct_orders
    description: >
      Order-level fact table joining Stripe payments with Shopify orders.
      Grain: one row per order. Refreshed daily via incremental append.
    columns:
      - name: order_id
        description: "Primary key. Unique Shopify order identifier."
        data_tests: [unique, not_null]
      - name: total_amount
        description: "Order total in USD after discounts, before tax."
```

### Column-Level Documentation

Prioritize documenting:
- Primary and foreign keys
- Business-critical metrics (revenue, counts)
- Columns with non-obvious logic (calculated fields, status enums)
- Sensitive columns (tag with `meta.data_classification`)

### Documentation Completeness Check

```bash
# Count models missing descriptions
dbt ls --resource-type model --output json | python -c "
import sys, json
models = [json.loads(l) for l in sys.stdin]
missing = [m['name'] for m in models if not m.get('description')]
print(f'{len(missing)} models missing descriptions: {missing[:5]}')
"
```
